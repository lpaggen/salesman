{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSPIRATION FROM THE FOLLOWING BLOG \n",
    "\n",
    "https://medium.com/aimonks/traveling-salesman-problem-tsp-using-genetic-algorithm-fea640713758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up country list\n",
    "\n",
    "cities = [\n",
    "    \"Paris\", \"Berlin\", \"London\", \"Madrid\", \"Rome\", \"Amsterdam\", \"Lisbon\", \"Prague\", \"Vienna\", \"Stockholm\",\n",
    "]\n",
    "\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Paris': (14, 16),\n",
       " 'Berlin': (7, 9),\n",
       " 'London': (10, 9),\n",
       " 'Madrid': (16, 17),\n",
       " 'Rome': (6, 16),\n",
       " 'Amsterdam': (6, 17),\n",
       " 'Lisbon': (6, 7),\n",
       " 'Prague': (1, 19),\n",
       " 'Vienna': (11, 4),\n",
       " 'Stockholm': (3, 9)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_coords(city_list, max_distance):\n",
    "    country_coords = {}\n",
    "    for city in city_list:\n",
    "        while len(country_coords) < len(city_list):\n",
    "            coords = (randrange(0, max_distance), randrange(0, max_distance))\n",
    "            if coords not in country_coords.values():\n",
    "                country_coords[city] = coords\n",
    "                break\n",
    "\n",
    "    return country_coords\n",
    "\n",
    "coords = determine_coords(cities, 20)\n",
    "print(len(coords))\n",
    "\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of above countries, select N countries to construct initial population\n",
    "\n",
    "def initial_countries(n_sol, n_countries, country_list):\n",
    "    selected_cities = []  # list of n countries to permute\n",
    "    while len(selected_cities) < n_sol:\n",
    "        sublist_cities = []  # list of n countries to permute\n",
    "        while len(sublist_cities) < n_countries:\n",
    "            rand = randrange(0, len(country_list))\n",
    "            selected_city = country_list[rand]\n",
    "            if selected_city not in sublist_cities:\n",
    "                sublist_cities.append(selected_city)\n",
    "        if len(set(sublist_cities)) == n_countries:  # Ensure unique cities\n",
    "            selected_cities.append(sublist_cities)\n",
    "\n",
    "    return selected_cities\n",
    "\n",
    "cities_selection = initial_countries(100, 10, cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Stockholm': (3, 9),\n",
       " 'Rome': (6, 16),\n",
       " 'Vienna': (11, 4),\n",
       " 'Amsterdam': (6, 17),\n",
       " 'Berlin': (7, 9),\n",
       " 'Paris': (14, 16),\n",
       " 'Madrid': (16, 17),\n",
       " 'Lisbon': (6, 7),\n",
       " 'Prague': (1, 19),\n",
       " 'London': (10, 9)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_pop_coords(solution_arr, coord_map):\n",
    "    result_dict_list = []\n",
    "\n",
    "    for subarray in solution_arr:\n",
    "        subarray_dict = {city: coord_map.get(city, None) for city in subarray}\n",
    "        result_dict_list.append(subarray_dict)\n",
    "\n",
    "    return result_dict_list\n",
    "\n",
    "solutions_coords = construct_pop_coords(cities_selection, coords)\n",
    "\n",
    "solutions_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_dist(sol_coords):\n",
    "    max_range = len(sol_coords[0]) - 1\n",
    "    total_dist_per_sol = []\n",
    "    for sol_coord in sol_coords:\n",
    "        solution_total_dist = 0\n",
    "        for i in range(max_range):\n",
    "            city_1_coords = list(sol_coord.values())[i]\n",
    "            city_2_coords = list(sol_coord.values())[i + 1]\n",
    "            \n",
    "            distance = dist(city_1_coords, city_2_coords)\n",
    "            solution_total_dist += distance \n",
    "            \n",
    "        total_dist_per_sol.append(solution_total_dist)\n",
    "    return total_dist_per_sol\n",
    "        \n",
    "total_distances_per_sol = calc_total_dist(solutions_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_weights(distance_sum_list):\n",
    "    score_list = []\n",
    "    for distance_sum in distance_sum_list:\n",
    "        score_list.append(1 / (1 + distance_sum))\n",
    "\n",
    "    return score_list\n",
    "\n",
    "weights = assign_weights(total_distances_per_sol)\n",
    "\n",
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_wheel(solutions, weights_list):\n",
    "    total_score = sum(weights_list)\n",
    "    probabilities = [x / total_score for x in weights_list] # gets proportion of each solution based on score (adds to 1)\n",
    "    selection = []\n",
    "    for i in range(len(solutions)):\n",
    "        rand = random() # number between 0 and 1\n",
    "        prob_sum = 0 # cumulative probability\n",
    "        for idx, prob in enumerate(probabilities):\n",
    "            prob_sum += prob # adds up to total\n",
    "            if prob_sum > rand: # cutoff is exceeded\n",
    "                selection.append(solutions[idx])\n",
    "                break\n",
    "\n",
    "    return selection\n",
    "\n",
    "selected_solutions = probability_wheel(solutions_coords, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(solutions, cross_rate): # TO DO : IMPLEMENT CROSSOVER RATE\n",
    "    parents = [(solutions[i], solutions[i + 1]) for i in range(0, len(solutions), 2)]\n",
    "    cross_solutions = [] # store the newly crossovered solutions\n",
    "    for parent1, parent2 in parents:\n",
    "        sub_cross_solutions_c1 = {}\n",
    "        sub_cross_solutions_c2 = {}\n",
    "\n",
    "        p1_city = [city for city in parent1.keys()]\n",
    "        p2_city = [city for city in parent2.keys()]\n",
    "        p1_coords = [coord for coord in parent1.values()]\n",
    "        p2_coords = [coord for coord in parent2.values()]\n",
    "\n",
    "        rand = randrange(1, len(solutions[0]))\n",
    "\n",
    "        child_1_cities_cross = p1_city[:rand]\n",
    "        child_2_cities_cross = p2_city[rand:]\n",
    "        child_1_coord_cross = p1_coords[:rand]\n",
    "        child_2_coord_cross = p2_coords[rand:]\n",
    "\n",
    "        # this was in fact found in the blog mentioned in the sources above, i was just unaware the \"+=\" could be used on lists\n",
    "        child_1_cities_cross += [city for city in child_2_cities_cross if city not in child_1_cities_cross]\n",
    "        child_2_cities_cross += [city for city in child_1_cities_cross if city not in child_2_cities_cross]\n",
    "        child_1_coord_cross += [coord for coord in child_2_coord_cross if coord not in child_1_coord_cross]\n",
    "        child_2_coord_cross += [coord for coord in child_1_coord_cross if coord not in child_2_coord_cross]\n",
    "\n",
    "        # this block of code reverts the crossover if there were any duplicates (code above was problematic)\n",
    "        if child_1_cities_cross != len(p1_city):\n",
    "            child_1_cities_cross = list(parent1.keys()) # if unable to get to length 10, kill crossover\n",
    "            child_1_coord_cross = list(parent1.values())\n",
    "        if child_2_cities_cross != len(p2_city):\n",
    "            child_2_cities_cross = list(parent2.keys())\n",
    "            child_2_coord_cross = list(parent2.values())\n",
    "\n",
    "        for idx, city in enumerate(child_1_cities_cross):\n",
    "            sub_cross_solutions_c1[city] = child_1_coord_cross[idx]\n",
    "        for idx, city in enumerate(child_2_cities_cross):\n",
    "            sub_cross_solutions_c2[city] = child_2_coord_cross[idx]\n",
    "\n",
    "        cross_solutions.append(sub_cross_solutions_c1)\n",
    "        cross_solutions.append(sub_cross_solutions_c2)\n",
    "\n",
    "    return cross_solutions\n",
    "\n",
    "cross_sample = crossover(selected_solutions, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(city_coord_map, solutions, mutate_rate):\n",
    "    mutated_solutions = []\n",
    "    city_names = [city for city in city_coord_map.keys()]\n",
    "    city_coords = [coords for coords in city_coord_map.values()]\n",
    "    for solution in solutions:\n",
    "        cities = [city for city in solution.keys()]\n",
    "        coords = [coord for coord in solution.values()]\n",
    "        for idx, current_city in enumerate(cities):\n",
    "            rand = random()\n",
    "            rand_idx = randrange(0, len(city_coord_map))\n",
    "            new_city = city_names[rand_idx]\n",
    "            new_coord = city_coords[rand_idx]\n",
    "            if rand < mutate_rate and new_city not in cities:\n",
    "                cities[idx] = new_city\n",
    "                coords[idx] = new_coord\n",
    "\n",
    "        mutated_solutions.append(dict(zip(cities, coords))) # maybe refactor this thing at some point if we want to\n",
    "\n",
    "    return mutated_solutions\n",
    "\n",
    "mutated_results = mutate(coords, cross_sample, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Stockholm': (16, 14), 'Amsterdam': (9, 18), 'Rome': (9, 17), 'Madrid': (8, 14), 'Paris': (10, 12), 'Vienna': (10, 11), 'London': (10, 10), 'Berlin': (9, 6), 'Prague': (19, 13), 'Lisbon': (16, 15)}\n",
      "36.98817505002847\n"
     ]
    }
   ],
   "source": [
    "def genetic_algorithm(cities, max_distance, n_sol, n_cities, n_iterations, cross_rate, mutate_rate):\n",
    "    coords = determine_coords(cities, max_distance)\n",
    "    cities_selection = initial_countries(n_sol, n_cities, cities)\n",
    "    solutions_coords = construct_pop_coords(cities_selection, coords)\n",
    "    \n",
    "    optimal_solution = None\n",
    "    optimal_dist = 10000\n",
    "    optimal_score = 0\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        total_distances = calc_total_dist(solutions_coords)\n",
    "        weights = assign_weights(total_distances)\n",
    "        selected_solutions = probability_wheel(solutions_coords, weights)\n",
    "\n",
    "        crossover_results = crossover(selected_solutions, cross_rate)\n",
    "\n",
    "        mutated_results = mutate(coords, crossover_results, mutate_rate)\n",
    "\n",
    "        total_distances_after_algo = calc_total_dist(mutated_results)\n",
    "        weights_new_gen = assign_weights(total_distances_after_algo)\n",
    "\n",
    "        best_dist = total_distances_after_algo[np.argmax(weights_new_gen)]\n",
    "        best_sol = mutated_results[np.argmax(weights_new_gen)]\n",
    "\n",
    "        if best_dist < optimal_dist:\n",
    "            optimal_dist = best_dist\n",
    "            optimal_solution = best_sol\n",
    "\n",
    "        solutions_coords = mutated_results\n",
    "\n",
    "    print(optimal_solution)\n",
    "    print(optimal_dist)\n",
    "\n",
    "genetic_algorithm(cities = cities, max_distance = 20, n_sol = 100, n_cities = 10, n_iterations = 10000, cross_rate = 0.4, mutate_rate = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
